{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oXE3W1jGY0W4",
        "outputId": "57cb92dc-7e9c-472f-aeb7-72b31df57106"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'pretrained_pipeline.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2401275633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1️⃣ Load pretrained pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained_pipeline.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pretrained_pipeline.pkl'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "df = pd.read_csv('sample.csv', nrows=20000)  # limit to 20k rows for speed\n",
        "df = df[['text']]  # keep only tweet text\n",
        "\n",
        "# 2️⃣ AUTOMATICALLY LABEL CATEGORIES\n",
        "def label_category(text):\n",
        "    text = str(text).lower()\n",
        "    # Billing keywords\n",
        "    if any(word in text for word in ['invoice','bill','payment','charge','refund','money']):\n",
        "        return 'Billing'\n",
        "    #Technical keywords\n",
        "    elif any(word in text for word in ['error','bug','crash','loading','website','screen','wifi','connection']):\n",
        "        return 'Technical'\n",
        "    # Account keywords\n",
        "    elif any(word in text for word in ['account','password','login','profile','username','email','reset','delete']):\n",
        "        return 'Account'\n",
        "    else:\n",
        "        return None  # ignore tweets that don't match\n",
        "\n",
        "df['category'] = df['text'].apply(label_category)\n",
        "df = df[df['category'].notnull()].reset_index(drop=True)\n",
        "\n",
        "# 3️⃣ TF-IDF FEATURE EXTRACTION\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=30000)\n",
        "X = tfidf.fit_transform(df['text'])\n",
        "y = df['category']\n",
        "\n",
        "# 4️⃣ TRAIN LOGISTIC REGRESSION MODEL\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X, y)\n",
        "\n",
        "# List of words the model knows\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "\n",
        "# 5️⃣ INTERACTIVE PREDICTION FUNCTION\n",
        "def analyze_message():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    user_input = input(\"Enter your support message (or type 'exit' to quit): \")\n",
        "\n",
        "    if not user_input.strip() or user_input.lower() == 'exit':\n",
        "        return False  # stop the loop\n",
        "\n",
        "    input_tfidf = tfidf.transform([user_input])\n",
        "\n",
        "    if input_tfidf.nnz == 0:\n",
        "        print(\"RESULT: Unknown\")\n",
        "        print(\"REASON: None of these words were in the training data.\")\n",
        "        return True\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_tfidf)[0]\n",
        "\n",
        "    # Find influential keywords\n",
        "    class_index = list(model.classes_).index(prediction)\n",
        "    weights = model.coef_[class_index]\n",
        "    row_data = input_tfidf.toarray()[0]\n",
        "    impact_scores = row_data * weights\n",
        "    important_indices = np.argsort(impact_scores)[::-1]\n",
        "\n",
        "    keywords = []\n",
        "    for i in important_indices:\n",
        "        if impact_scores[i] > 0:\n",
        "            keywords.append(f\"{feature_names[i]} (score: {impact_scores[i]:.2f})\")\n",
        "\n",
        "    # Output\n",
        "    print(f\"\\nPREDICTED CATEGORY: {prediction}\")\n",
        "    print(f\"INFLUENTIAL KEYWORDS: {', '.join(keywords[:3])}\")  # top 3 words\n",
        "    print(\"=\"*50)\n",
        "    return True\n",
        "\n",
        "# 6️⃣ RUN INTERACTIVE LOOP\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"System Ready. Type 'exit' to stop.\")\n",
        "    while True:\n",
        "        if not analyze_message():\n",
        "            break\n",
        "\n"
      ]
    }
  ]
}